{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8247c1-8bcc-4d4a-88b7-aec235dfff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from pyspark.sql.functions import col, regexp_replace, when, expr\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Transform and Combine Partitioned Files\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# HDFS paths\n",
    "input_directory = \"hdfs://namenode:9000/data\"\n",
    "\n",
    "# List of file names (file1.csv, file2.csv, ..., fileN.csv)\n",
    "num_files = 1  # Change this to the actual number of files\n",
    "file_names = [\"sample.csv\"]\n",
    "\n",
    "\n",
    "# Iterate over each file and transform\n",
    "for file_name in file_names:\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(input_directory, file_name)\n",
    "    \n",
    "    # Load the file into a DataFrame\n",
    "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "data = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e7c42-42ac-491b-ae23-e3ffc9b5ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['Age'] = pd.to_numeric(data['Age'], errors='coerce')\n",
    "# data['Quantity'] = pd.to_numeric(data['Quantity'], errors='coerce')\n",
    "# data['TotalAmount'] = pd.to_numeric(data['TotalAmount'], errors='coerce')\n",
    "# data['Price'] = pd.to_numeric(data['Price'], errors='coerce')\n",
    "# data['Country'] = data['Country'].astype(str)\n",
    "# data['CustomerID'] = data['CustomerID'].astype(int)\n",
    "# data['Name'] = data['Name'].astype(str)\n",
    "# data['RegistrationDate'] = pd.to_datetime(data['RegistrationDate'], errors='coerce')\n",
    "# data['OrderDate'] = pd.to_datetime(data['OrderDate'], errors='coerce')\n",
    "# data['Category'] = data['Category'].astype(str)\n",
    "# data['ProductID'] = data['ProductID'].astype(int)\n",
    "# data['ProductName'] = data['ProductName'].astype(str)\n",
    "# data['ShippingAddress'] = data['ShippingAddress'].astype(str)\n",
    "# data['ShippingDate'] = pd.to_datetime(data['ShippingDate'], errors='coerce')\n",
    "\n",
    "data['Age'] = data['Age'].astype(int)  # Convert to numeric (float)\n",
    "data['Quantity'] = data['Quantity'].astype(int)  # Convert to numeric (float)\n",
    "data['TotalAmount'] = data['TotalAmount'].astype(float)  # Convert to numeric (float)\n",
    "data['Price'] = data['Price'].astype(float)  # Convert to numeric (float)\n",
    "data['Country'] = data['Country'].astype(str)  # Convert to string\n",
    "data['CustomerID'] = data['CustomerID'].astype(int)  # Convert to integer\n",
    "data['Name'] = data['Name'].astype(str)  # Convert to string\n",
    "data['RegistrationDate'] = data['RegistrationDate'].astype('datetime64[ns]')  # Convert to datetime\n",
    "data['OrderDate'] = data['OrderDate'].astype('datetime64[ns]')  # Convert to datetime\n",
    "data['Category'] = data['Category'].astype(str)  # Convert to string\n",
    "data['ProductID'] = data['ProductID'].astype(int)  # Convert to integer\n",
    "data['ProductName'] = data['ProductName'].astype(str)  # Convert to string\n",
    "data['ShippingAddress'] = data['ShippingAddress'].astype(str)  # Convert to string\n",
    "data['ShippingDate'] = data['ShippingDate'].astype('datetime64[ns]')  # Convert to datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade52cd-f53a-4b9a-b521-8edd7d313331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667b6da-ee99-4a0c-a74b-a1c54bb6eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print('start')\n",
    "\n",
    "# Convert PySpark DataFrame to pandas DataFrame\n",
    "\n",
    "\n",
    "# Identify numerical columns\n",
    "numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, axs = plt.subplots(nrows=len(numerical_cols), ncols=3, figsize=(18, len(numerical_cols) * 5))\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    # Boxplot\n",
    "    axs[i, 0].boxplot(data[col].dropna())\n",
    "    axs[i, 0].set_title(f'Boxplot of {col}')\n",
    "    axs[i, 0].set_ylabel(col)\n",
    "    \n",
    "    # Histogram\n",
    "    axs[i, 1].hist(data[col].dropna(), bins=30, edgecolor='black')\n",
    "    axs[i, 1].set_title(f'Histogram of {col}')\n",
    "    axs[i, 1].set_ylabel('Frequency')\n",
    "\n",
    "    # Density plot\n",
    "    sns.kdeplot(data[col].dropna(), ax=axs[i, 2], fill=True)\n",
    "    axs[i, 2].set_title(f'Density Plot of {col}')\n",
    "    axs[i, 2].set_ylabel('Density')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a687a9-86e5-47a3-813e-dfcce4a5a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_columns = ['Quantity', 'Age', 'Price', 'TotalAmount']\n",
    "\n",
    "# Initialize dictionaries to store bounds and outlier counts\n",
    "outlier_bounds = {}\n",
    "outlier_counts = {}\n",
    "\n",
    "# Calculate Q1, Q2, Q3, and outliers for each numeric column\n",
    "for col in numeric_columns:\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q2 = data[col].quantile(0.50)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "    \n",
    "    # Calculate IQR\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define lower and upper bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outlier_bounds[col] = (lower_bound, upper_bound)\n",
    "    \n",
    "    # Count the number of outliers\n",
    "    outlier_count = data[(data[col] < lower_bound) | (data[col] > upper_bound)].shape[0]\n",
    "    outlier_counts[col] = outlier_count\n",
    "\n",
    "# Show outlier bounds\n",
    "for col, bounds in outlier_bounds.items():\n",
    "    print(f\"{col}: Lower Bound = {bounds[0]}, Upper Bound = {bounds[1]}\")\n",
    "\n",
    "# Show count of outliers for each numeric column\n",
    "for col, count in outlier_counts.items():\n",
    "    print(f\"{col}: Outlier Count = {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9334d7cd-200c-48f5-ba52-817503726fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start')\n",
    "def check_missing_data(df):\n",
    "    missing_summary = df.isnull().sum()\n",
    "    missing_percentage = (missing_summary / len(df)) * 100\n",
    "\n",
    "    print(\"Missing Values Summary:\")\n",
    "    print(pd.DataFrame({\n",
    "        'Missing Count': missing_summary,\n",
    "        'Percentage': missing_percentage\n",
    "    }))\n",
    "    \n",
    "    return missing_summary, missing_percentage\n",
    "\n",
    "missing_summary, missing_percentage = check_missing_data(data)\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97723c51-754c-44b8-9dae-8033b0d22e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start')\n",
    "selected_cols = [\n",
    "    'Quantity', \n",
    "    'Age', \n",
    "    'Price', \n",
    "    'TotalAmount', \n",
    "]\n",
    "\n",
    "correlation_matrix = data[selected_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', \n",
    "            vmin=-1, vmax=1, square=True, linewidths=.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Display the correlation table\n",
    "print(\"Correlation Table:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2aced7-baaf-465d-9819-0e2e3ce07f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_product_names = df.select(\"ProductName\").distinct().collect()\n",
    "distinct_countries = df.select(\"Country\").distinct().collect()\n",
    "\n",
    "# Print the distinct values\n",
    "print(\"Distinct Product Names:\")\n",
    "for row in distinct_product_names:\n",
    "    print(row[\"ProductName\"])\n",
    "\n",
    "print(\"\\nDistinct Countries:\")\n",
    "for row in distinct_countries:\n",
    "    print(row[\"Country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f77e56-cde4-4c59-831c-5ceef7bd0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = df.columns\n",
    "print(\"Headers of the DataFrame:\", headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44c34b8-057f-4d44-ba49-c9375585c0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
